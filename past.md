---
layout: page
title: Past Talks
order: 4
---

<!-- ## Past Talks and Recordings -->

* Thursday, May 19th, 2022 - **Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game** by [Alexander Reisach](https://linkedin.com/in/alexander-reisach-2033a9175) [[Recording](https://drive.google.com/file/d/1WpcHS3bJUCyPpGSSDYF0fsSZVMKNM3nR)] [[Slides](../files/slides/2022_05_19-CausalTau.pdf)]
  * **Abstract**: Simulated DAG models may exhibit properties that, perhaps inadvertently, render their structure identifiable and unexpectedly affect structure learning algorithms. Here, we show that marginal variance tends to increase along the causal order for generically sampled additive noise models. We introduce varsortability as a measure of the agreement between the order of increasing marginal variance and the causal order. For commonly sampled graphs and model parameters, we show that the remarkable performance of some continuous structure learning algorithms can be explained by high varsortability and matched by a simple baseline method. Yet, this performance may not transfer to real-world data where varsortability may be moderate or dependent on the choice of measurement scales. On standardized data, the same algorithms fail to identify the ground-truth DAG or its Markov equivalence class. While standardization removes the pattern in marginal variance, we show that data generating processes that incur high varsortability also leave a distinct covariance pattern that may be exploited even after standardization. Our findings challenge the significance of generic benchmarks with independently drawn parameters.
  * **Reference**
    * Reisach, Alexander, Christof Seiler, and Sebastian Weichwald. [Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game](https://proceedings.neurips.cc/paper/2021/file/e987eff4a7c7b7e580d659feb6f60c1a-Paper.pdf). In Advances in Neural Information Processing Systems, 34:27772–84. 2021.
  * **Bio**: [Alexander Reisach](https://linkedin.com/in/alexander-reisach-2033a9175) is a Research Engineer at CentraleSupélec. His work focuses broadly on causal inference, including causal structure learning from interventions and machine learning.

* Thursday, April 7th, 2022 - **Generative Neural Networks for Observational Causal Discovery** by [Diviyan Kalainathan](https://diviyan-kalainathan.github.io/) [[Recording](#)] [[Slides](#)]  
  * **Abstract**: Causal discovery is of utmost importance for agents who must plan, reason and decide based on observations; where mistaking correlation with causation might lead to unwanted consequences. The gold standard to discover causal relations is to perform experiments. However, experiments are in many cases expensive, unethical, or impossible to realize. In these situations, there is a need for observational causal discovery, that is, the estimation of causal relations from observations alone.
  We will go through the traditional methods to find causal relationships in observational data: conditional independence, Occam's razor., among others. Causal discovery in the observational data setting traditionally involves making significant assumptions on the data and on the underlying causal model. This work aims to alleviate some assumptions made on the causal models by exploiting the modularity and expressiveness of neural networks for causal discovery, leveraging both conditional independencies and simplicity of the causal mechanisms.
  * **References**
    * Patrik O. Hoyer, Dominik Janzing, Joris M. Mooij, Jonas Peters, and Bernhard Schölkopf. [Nonlinear causal discovery with additive noise models](https://papers.nips.cc/paper/2008/hash/f7664060cc52bc6f3d620bcedc94a4b6-Abstract.html). In Neural Information Processing Systems (NIPS), pages 689–696, 2009.
    * Kalainathan, D., Goudet, O., & Dutta, R. (2020). [Causal Discovery Toolbox: Uncovering causal relationships in Python](https://jmlr.org/papers/v21/19-187.html). J. Mach. Learn. Res., 21, 37-1.
    * Goudet, Olivier, Diviyan Kalainathan, Philippe Caillou, Isabelle Guyon, David Lopez-Paz, and Michèle Sebag (2017). [Causal generative neural networks](https://arxiv.org/abs/1711.08936). arXiv:1711.08936
  * **Bio**: [Diviyan Kalainathan](https://diviyan-kalainathan.github.io/) is a Data Scientist at Fentech. He received a PhD degree in Computer Science from the Université Paris-Saclay in 2019 under the direction of Isabelle Guyon, Michèle Sebag, and Philippe Caillou. His works mainly focus on causal discovery of observational data and neural networks for social sciences in the directed graph setting. His interests also include generative models and reinforcement learning.

* Thursday, March 3rd, 2022 - **Causal Discovery in Observational Time Series** by [Emilie Devijver](http://ama.liglab.fr/~devijver/) (CNRS researcher at Université Grenoble Alpes) [[Recording]()] [[Slides]()]
  * **Abstract**: Time series arise as soon as observations, from sensors or experiments, for example, are collected over time. They are present in various forms in many different domains, as healthcare (through, e.g., monitoring systems), Industry 4.0 (through, e.g., predictive maintenance and industrial monitoring systems), surveillance systems (from images, acoustic signals, seismic waves, etc.) or energy management (through, e.g. energy consumption data). In this talk, we first introduce the main methods proposed recently, based on different approaches (Granger causality, constraint-based approaches, noise-based approaches). Then, we propose a new method, seen as a hybrid between the noise-based framework to find potential causes of each time series, and the well-known constraint-based framework to prune all unnecessary causes. By doing so, we rely on a lighter version of the faithfulness hypothesis, namely the adjacency hypothesis. Experiments conducted on both simulated and real-world time series illustrate all the presented approaches.
  * **References**:
    * Assaad, C. K., Devijver, E., and Gaussier, E. (2022). [Survey and evaluation of causal discovery methods for time series](https://www.jair.org/index.php/jair/article/view/13428). Journal of Artificial Intelligence Research, 73:767–819.
    * K. Assaad, E. Devijver, É. Gaussier, and A. Aït-Bachir, [A mixed noise and constraint-based approach to causal inference in time series](https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_896.pdf), in Machine learning and knowledge discovery in databases. research track – European Conference, ECML PKDD 2021, Bilbao, Spain, September 13-17, 2021, proceedings, part I, 2021, p. 453–468.
  * **Bio**: [Emilie Devijver](http://ama.liglab.fr/~devijver/) is a CNRS researcher at the Computer Science department of the Université Grenoble Alpes, in the AMA team. Prior to that, she completed postdoctoral studies at Katholieke Universiteit Leuven, Belgium, in 2017 under the supervision of Irène Gijbels. She received a PhD degree in mathematics from the Paris-Sud University in 2015 under the direction of ​​Pascal Massart and Jean-Michel Poggi. Her works mainly focus on the field of statistical learning, with a methodological, theoretical, and application viewpoint.

* Thursday, February 3rd, 2022 - **Domain Generalization in a Causal Perspective: Deconfounding the Domain Biases** by [Shiyang Yan]() (INRIA, TAU Team) [[Recording]()] [[Slides](../files/slides/Yan_Sebag_Domain-Generalization-in-a-Causal-Perspective_Deconfounding-the-Domain-Biases.pptx)]
  * **Abstract**: Domain Generalization (DG), focusing on out-of-distribution generalization (Wang et al., 2021), aims to train a model on several source domains, and apply it on an unknown target domain. DG faces a key difficulty, the fact that each source domain suffers from a dataset bias. The contribution of the paper is to tackle DG in a causal perspective, where the source biases are viewed as confounders. Taking inspiration from the Deconfounder approach (Wang and Blei 2019, 2021), a non-linear independent component analysis (ICA) is used to learn substitute hidden confounders (SHCs). To mitigate the non-identifiability of the SHCs,  a novel adversarial contrastive learning scheme is used to learn domain invariant and mutually independent SHCs. The merits of the approach are comparatively demonstrated on several challenging DG benchmarks, yielding state-of-art performances. Ablation studies are conducted to determine the respective impact of the ICA model and of the contrastive learning scheme.
  * **References**
    * Wang, Y. and Blei, D. M. [The blessings of multiple causes](https://www.tandfonline.com/doi/full/10.1080/01621459.2019.1686987). Journal of the American Statistical Association, 114(528): 1574–1596, 2019.
    * Wang, Z., Loog, M., and van Gemert, J. [Respecting domain relations: Hypothesis invariance for domain generalization](https://arxiv.org/abs/2010.07591). In The International Conference on Pattern Recognition (ICPR), 2021.
  * **Bio**: [Shiyang Yan]() is presently a postdoc researcher in the TAU research team of the National Institute for Research in Digital Science and Technology (INRIA), Paris, France. Prior to that, he worked as a university lecturer at NUIST, China from 2020 to 2021. Previously, he has worked as a postdoc researcher at Queen’s University Belfast, UK from 2019-2020. He received a Ph.D. degree from the University of Liverpool, UK, in 2018. He received his Master's degree from Hohai University in 2015. His research interests include causal inference, reinforcement learning, and attention mechanism.

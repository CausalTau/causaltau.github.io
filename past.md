---
layout: page
title: Past Talks
order: 4
---

<!-- ## Past Talks and Recordings -->

* Thursday, September 1st and September 22nd, 2022 - **Definition and estimation of a variable importance measure of a continuous exposure** by [Antoine Chambaz](https://helios2.mi.parisdescartes.fr/~chambaz/index.php?choix=1) (Université Paris Cité) [[Recording of the first session]](https://drive.google.com/file/d/1ZumH45Y9bTHl325aZseC9kLOoMvuWwNh/view)
  * **Abstract**: In [1,2] we defined a new measure of variable importance of an exposure on a continuous outcome, accounting for potential confounders, when the exposure features a reference level x0 with positive mass and a continuum of other levels. We also showed how to build asymptotic confidence intervals for it, using the semi-parametric estimation methodology called targeted minimum loss estimation methodology (TMLE) [3,4,5]. In the application, which motivated the study, the exposure and response are, respectively, the DNA copy number and expression level of a given gene in a cancer cell. The reference level is $$x_0=2$$, that is the expected DNA copy number in a normal cell. As for the confounder, it is a measure of the methylation of the gene.
  This two-part talk will present and discuss the theoretical, computational and applied facets of the study.
  * **References**:
    1. Chambaz, Neuvial and van der Laan, [Estimation of a non-parametric variable importance measure of a continuous exposure](https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-6/issue-none/Estimation-of-a-non-parametric-variable-importance-measure-of-a/10.1214/12-EJS703.full
), Electron.  J. Stat., 6:1059-1099 (2012)
    2. Chambaz and Neuvial, [tmle.npvi: targeted, integrative search of associations between DNA copy number and gene expression, accounting for DNA methylation](https://academic.oup.com/bioinformatics/article/31/18/3054/241218), Bioinformatics, 31(18):3054-3056 (2015)
    3. van der Laan and Rubin, [Targeted maximum likelihood learning](https://biostats.bepress.com/ucbbiostat/paper213/), Int. J. Biostat., 2:Article 11 (2006)
    4. van der Laan and Rose, [Targeted Learning: Causal Inference for Observational and Experimental Data](https://link.springer.com/book/10.1007/978-1-4419-9782-1), Springer Verlag (2011)
    5. van der Laan and Rose, [Targeted Learning in Data Science: Causal Inference for Complex Longitudinal Studies](https://link.springer.com/book/10.1007/978-3-319-65304-4), Springer Verlag (2018)

* Thursday, June 02nd and June 23rd, 2022 - **Heterogeneous Treatment Effects Estimation: When Machine Learning meets multiple treatments regime** by [Naoufal Acharki](https://nacharki.github.io) (École Polytechnique and TotalEnergies) **Recordings**: [[June 2nd](https://drive.google.com/file/d/1BI_xs0X21ovGO24dqGhsEQEFvCC67MUX)] and [[June 23rd](https://drive.google.com/file/d/13-YI96evifln00PwFEUO-yN23APXM7zG/view)] **Slides**: [[June 2nd](../files/slides/Acharki_2022_CausalTAU_June02.pdf)] and [[June 23rd](../files/slides/Acharki_2022_CausalTAU_June23.pdf)]
  - **Abstract**: In many scientific and engineering domains, inferring the effect of treatment and exploring its heterogeneity is crucial for optimization and decision making. In addition to Machine Learning based models (e.g. Random Forests or Neural Networks), many meta-algorithms have been developed to estimate the Conditional Average Treatment Effect (CATE) function in the binary setting, with the main advantage of not restraining the estimation to a specific supervised learning method. However, this task becomes more challenging when the treatment is not binary. In this paper, we investigate the Rubin Causal Model under the multiple treatment regime and we focus on estimating heterogeneous treatment effects. We generalize Meta-learning algorithms to estimate the CATE for each possible treatment value. Using synthetic and semi-synthetic simulation datasets, we assess the quality of each meta-learner in observational data, and we highlight in particular the performances of the X-learner.  
  * **Reference**
    * Acharki, Naoufal, Antoine Bertoncello, Josselin Garnier, and Ramiro Lugo. [_HETEROGENEOUS TREATMENT EFFECTS ESTIMATION: WHEN MACHINE LEARNING MEETS MULTIPLE TREATMENTS REGIME_](https://nacharki.github.io/files/Causal_Inference_multiple_treatments.pdf), 2022.


* Thursday, May 19th, 2022 - **Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game** by [Alexander Reisach](https://linkedin.com/in/alexander-reisach-2033a9175) [[Recording](https://drive.google.com/file/d/1WpcHS3bJUCyPpGSSDYF0fsSZVMKNM3nR)] [[Slides](../files/slides/2022_05_19-CausalTau.pdf)]
  * **Abstract**: Simulated DAG models may exhibit properties that, perhaps inadvertently, render their structure identifiable and unexpectedly affect structure learning algorithms. Here, we show that marginal variance tends to increase along the causal order for generically sampled additive noise models. We introduce varsortability as a measure of the agreement between the order of increasing marginal variance and the causal order. For commonly sampled graphs and model parameters, we show that the remarkable performance of some continuous structure learning algorithms can be explained by high varsortability and matched by a simple baseline method. Yet, this performance may not transfer to real-world data where varsortability may be moderate or dependent on the choice of measurement scales. On standardized data, the same algorithms fail to identify the ground-truth DAG or its Markov equivalence class. While standardization removes the pattern in marginal variance, we show that data generating processes that incur high varsortability also leave a distinct covariance pattern that may be exploited even after standardization. Our findings challenge the significance of generic benchmarks with independently drawn parameters.
  * **Reference**
    * Reisach, Alexander, Christof Seiler, and Sebastian Weichwald. [Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game](https://proceedings.neurips.cc/paper/2021/file/e987eff4a7c7b7e580d659feb6f60c1a-Paper.pdf). In Advances in Neural Information Processing Systems, 34:27772–84. 2021.
  * **Bio**: [Alexander Reisach](https://linkedin.com/in/alexander-reisach-2033a9175) is a Research Engineer at CentraleSupélec. His work focuses broadly on causal inference, including causal structure learning from interventions and machine learning.

* Thursday, April 7th, 2022 - **Generative Neural Networks for Observational Causal Discovery** by [Diviyan Kalainathan](https://diviyan-kalainathan.github.io/) [[Recording](https://drive.google.com/file/d/1fRsO1NSGb1muoAAwl7qs-LRXu21Q43B1/view)]
  * **Abstract**: Causal discovery is of utmost importance for agents who must plan, reason and decide based on observations; where mistaking correlation with causation might lead to unwanted consequences. The gold standard to discover causal relations is to perform experiments. However, experiments are in many cases expensive, unethical, or impossible to realize. In these situations, there is a need for observational causal discovery, that is, the estimation of causal relations from observations alone.
  We will go through the traditional methods to find causal relationships in observational data: conditional independence, Occam's razor., among others. Causal discovery in the observational data setting traditionally involves making significant assumptions on the data and on the underlying causal model. This work aims to alleviate some assumptions made on the causal models by exploiting the modularity and expressiveness of neural networks for causal discovery, leveraging both conditional independencies and simplicity of the causal mechanisms.
  * **References**
    * Patrik O. Hoyer, Dominik Janzing, Joris M. Mooij, Jonas Peters, and Bernhard Schölkopf. [Nonlinear causal discovery with additive noise models](https://papers.nips.cc/paper/2008/hash/f7664060cc52bc6f3d620bcedc94a4b6-Abstract.html). In Neural Information Processing Systems (NIPS), pages 689–696, 2009.
    * Kalainathan, D., Goudet, O., & Dutta, R. (2020). [Causal Discovery Toolbox: Uncovering causal relationships in Python](https://jmlr.org/papers/v21/19-187.html). J. Mach. Learn. Res., 21, 37-1.
    * Goudet, Olivier, Diviyan Kalainathan, Philippe Caillou, Isabelle Guyon, David Lopez-Paz, and Michèle Sebag (2017). [Causal generative neural networks](https://arxiv.org/abs/1711.08936). arXiv:1711.08936
  * **Bio**: [Diviyan Kalainathan](https://diviyan-kalainathan.github.io/) is a Data Scientist at Fentech. He received a PhD degree in Computer Science from the Université Paris-Saclay in 2019 under the direction of Isabelle Guyon, Michèle Sebag, and Philippe Caillou. His works mainly focus on causal discovery of observational data and neural networks for social sciences in the directed graph setting. His interests also include generative models and reinforcement learning.

* Thursday, March 3rd, 2022 - **Causal Discovery in Observational Time Series** by [Emilie Devijver](http://ama.liglab.fr/~devijver/) (CNRS researcher at Université Grenoble Alpes)
  * **Abstract**: Time series arise as soon as observations, from sensors or experiments, for example, are collected over time. They are present in various forms in many different domains, as healthcare (through, e.g., monitoring systems), Industry 4.0 (through, e.g., predictive maintenance and industrial monitoring systems), surveillance systems (from images, acoustic signals, seismic waves, etc.) or energy management (through, e.g. energy consumption data). In this talk, we first introduce the main methods proposed recently, based on different approaches (Granger causality, constraint-based approaches, noise-based approaches). Then, we propose a new method, seen as a hybrid between the noise-based framework to find potential causes of each time series, and the well-known constraint-based framework to prune all unnecessary causes. By doing so, we rely on a lighter version of the faithfulness hypothesis, namely the adjacency hypothesis. Experiments conducted on both simulated and real-world time series illustrate all the presented approaches.
  * **References**:
    * Assaad, C. K., Devijver, E., and Gaussier, E. (2022). [Survey and evaluation of causal discovery methods for time series](https://www.jair.org/index.php/jair/article/view/13428). Journal of Artificial Intelligence Research, 73:767–819.
    * K. Assaad, E. Devijver, É. Gaussier, and A. Aït-Bachir, [A mixed noise and constraint-based approach to causal inference in time series](https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_896.pdf), in Machine learning and knowledge discovery in databases. research track – European Conference, ECML PKDD 2021, Bilbao, Spain, September 13-17, 2021, proceedings, part I, 2021, p. 453–468.
  * **Bio**: [Emilie Devijver](http://ama.liglab.fr/~devijver/) is a CNRS researcher at the Computer Science department of the Université Grenoble Alpes, in the AMA team. Prior to that, she completed postdoctoral studies at Katholieke Universiteit Leuven, Belgium, in 2017 under the supervision of Irène Gijbels. She received a PhD degree in mathematics from the Paris-Sud University in 2015 under the direction of ​​Pascal Massart and Jean-Michel Poggi. Her works mainly focus on the field of statistical learning, with a methodological, theoretical, and application viewpoint.

* Thursday, February 3rd, 2022 - **Domain Generalization in a Causal Perspective: Deconfounding the Domain Biases** by [Shiyang Yan]() (INRIA, TAU Team) [[Slides](../files/slides/Yan_Sebag_Domain-Generalization-in-a-Causal-Perspective_Deconfounding-the-Domain-Biases.pptx)]
  * **Abstract**: Domain Generalization (DG), focusing on out-of-distribution generalization (Wang et al., 2021), aims to train a model on several source domains, and apply it on an unknown target domain. DG faces a key difficulty, the fact that each source domain suffers from a dataset bias. The contribution of the paper is to tackle DG in a causal perspective, where the source biases are viewed as confounders. Taking inspiration from the Deconfounder approach (Wang and Blei 2019, 2021), a non-linear independent component analysis (ICA) is used to learn substitute hidden confounders (SHCs). To mitigate the non-identifiability of the SHCs,  a novel adversarial contrastive learning scheme is used to learn domain invariant and mutually independent SHCs. The merits of the approach are comparatively demonstrated on several challenging DG benchmarks, yielding state-of-art performances. Ablation studies are conducted to determine the respective impact of the ICA model and of the contrastive learning scheme.
  * **References**
    * Wang, Y. and Blei, D. M. [The blessings of multiple causes](https://www.tandfonline.com/doi/full/10.1080/01621459.2019.1686987). Journal of the American Statistical Association, 114(528): 1574–1596, 2019.
    * Wang, Z., Loog, M., and van Gemert, J. [Respecting domain relations: Hypothesis invariance for domain generalization](https://arxiv.org/abs/2010.07591). In The International Conference on Pattern Recognition (ICPR), 2021.
  * **Bio**: [Shiyang Yan]() is presently a postdoc researcher in the TAU research team of the National Institute for Research in Digital Science and Technology (INRIA), Paris, France. Prior to that, he worked as a university lecturer at NUIST, China from 2020 to 2021. Previously, he has worked as a postdoc researcher at Queen’s University Belfast, UK from 2019-2020. He received a Ph.D. degree from the University of Liverpool, UK, in 2018. He received his Master's degree from Hohai University in 2015. His research interests include causal inference, reinforcement learning, and attention mechanism.
